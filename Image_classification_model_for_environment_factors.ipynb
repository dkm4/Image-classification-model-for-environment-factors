{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOYn8yc0BOXt1/5Z3zHKNox",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12c8070535de4ca28e2547de0b6c5980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_965a06c8ef6d4a03be3e9e27878bebd6",
              "IPY_MODEL_4c7079c670bf4ccbb9107ea1d4a75d70",
              "IPY_MODEL_b7b9f185a26e413e821d87df78112578"
            ],
            "layout": "IPY_MODEL_09ba7d59586a40659a2c910d11581f78"
          }
        },
        "965a06c8ef6d4a03be3e9e27878bebd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a880ee40f364ea4b9530202b160cd74",
            "placeholder": "​",
            "style": "IPY_MODEL_dd29213d0d61431aae17b7e5544f4ff3",
            "value": "100%"
          }
        },
        "4c7079c670bf4ccbb9107ea1d4a75d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35951615392449c49341cbc8e00a2439",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_443ef57959b34fbbb97b0f2f91b8003e",
            "value": 500
          }
        },
        "b7b9f185a26e413e821d87df78112578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a60a4460ccc44adb69d3f5701a44e7f",
            "placeholder": "​",
            "style": "IPY_MODEL_2689f2614f9c44cda41bc28543b5bbed",
            "value": " 500/500 [26:37&lt;00:00,  3.05s/it]"
          }
        },
        "09ba7d59586a40659a2c910d11581f78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a880ee40f364ea4b9530202b160cd74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd29213d0d61431aae17b7e5544f4ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35951615392449c49341cbc8e00a2439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "443ef57959b34fbbb97b0f2f91b8003e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a60a4460ccc44adb69d3f5701a44e7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2689f2614f9c44cda41bc28543b5bbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkm4/Image-classification-model-for-environment-factors/blob/main/Image_classification_model_for_environment_factors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#connect google drive\n"
      ],
      "metadata": {
        "id": "n79A9Lh7vN5w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWu9LIOPvL8_",
        "outputId": "3f36a6e4-8779-49e0-8447-24b9663ea6bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#check the dataset pathway\n"
      ],
      "metadata": {
        "id": "FiT34fYQvUhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/environment dataset'\n",
        "print(f\"data set pathway is {dataset_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TZe-89SvfkK",
        "outputId": "a8bdd687-75df-4eee-f746-9cd0ac5bac13"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data set pathway is /content/drive/MyDrive/environment dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#import"
      ],
      "metadata": {
        "id": "Pda9zm--vpl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbRT6_vYvoXA",
        "outputId": "e1240715-84b4-405f-c556-3a75e818db34"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n",
            "0.17.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#device"
      ],
      "metadata": {
        "id": "-vyPw-QCwkG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB5G4GbTwo0d",
        "outputId": "ddee73e0-62d1-4fd0-fbf1-ca8e06c6277b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#check the directory"
      ],
      "metadata": {
        "id": "y7m3kM7mw53S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(dataset_path))\n",
        "print(os.path.join(dataset_path,'train'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkwiz1LYxCxf",
        "outputId": "8f14e7dd-67e0-43a8-8ffa-4d819f9975fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train', 'test']\n",
            "/content/drive/MyDrive/environment dataset/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Connect the pathway to train, test data"
      ],
      "metadata": {
        "id": "IVPtMRxVxbX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_location = os.path.join(dataset_path,'train')\n",
        "test_data_location = os.path.join(dataset_path,'test')\n",
        "print(f\"my train data loction is: {train_data_location}\")\n",
        "print(f\"my test data loction is: {test_data_location}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1iYgoKlxgMv",
        "outputId": "8eb6faa7-194e-4cf9-e90c-87eee62cd424"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my train data loction is: /content/drive/MyDrive/environment dataset/train\n",
            "my test data loction is: /content/drive/MyDrive/environment dataset/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build dataset and dataloader by connecting pathway"
      ],
      "metadata": {
        "id": "ifr1Kry5ybcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#you take in the pathway to the train/test as an input and it returns the classes and the index of the classes inside the train/test dataset an output\n",
        "def find_classes(path_to_data):\n",
        "  classes = sorted(os.listdir(path_to_data))\n",
        "  class_to_idx = {c:i for i, c in enumerate(classes)}\n",
        "  return classes, class_to_idx\n"
      ],
      "metadata": {
        "id": "jpeL7hHz2_vq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#takes in the train/test pathway as an input and return all the image in train/test\n",
        "def give_me_all_images_path(data_location):\n",
        "  return glob.glob(os.path.join(data_location, '*', '*.*'), recursive=True)\n",
        "\n",
        "#give_me_all_images_path(train_data_location)"
      ],
      "metadata": {
        "id": "QBRnE7Aa3Aj5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pathToClass(path):\n",
        "  dir_path = os.path.dirname(path)\n",
        "  return os.path.basename(dir_path)\n"
      ],
      "metadata": {
        "id": "nZbIQzjr6Vqc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class ImageFolderCustom(Dataset):\n",
        "  def __init__(self, dataset_path, transform):\n",
        "    self.dataset_path = dataset_path\n",
        "    self.transform    = transform\n",
        "    self.classes, self.class_to_idx = find_classes(dataset_path)\n",
        "    self.paths = give_me_all_images_path(dataset_path)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    path = self.paths[idx]\n",
        "    img = Image.open(path)\n",
        "    my_class = pathToClass(path)\n",
        "    class_label = self.class_to_idx[my_class]\n",
        "    if self.transform:\n",
        "      return self.transform(img), class_label\n",
        "    else:\n",
        "      return img, class_label"
      ],
      "metadata": {
        "id": "cU3lNkCdydsr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "  transforms.Resize((32,32)),\n",
        "  transforms.RandomRotation(10),\n",
        "     transforms.ToTensor(),\n",
        " ])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((32,32)),\n",
        "    transforms.ToTensor(),\n",
        " ])"
      ],
      "metadata": {
        "id": "chLBjsTy6Uik"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ImageFolderCustom(train_data_location, transform = train_transform)\n",
        "test_dataset = ImageFolderCustom(test_data_location, transform = test_transform)"
      ],
      "metadata": {
        "id": "_duHfT0w7YEP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "NUM_CLASSES = 4\n",
        "train_data_loader = DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "test_data_loader = DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
        "\n"
      ],
      "metadata": {
        "id": "ChjoTy-280ic"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, i in enumerate(test_data_loader):\n",
        "  print(f\"batch:{batch_idx+1} and number of points are {len(i[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z1suqgUEaVU",
        "outputId": "a95d2fcf-9991-4fc6-dc9e-d72980e5d110"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch:1 and number of points are 8\n",
            "batch:2 and number of points are 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#build the NN architecture"
      ],
      "metadata": {
        "id": "mnZm7jVZGn3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class FashionNN(nn.Module):\n",
        "#   def __init__(self, in_features, out_features, hidden_layer=20):\n",
        "#     super().__init__()\n",
        "#     self.layer = nn.Sequential(\n",
        "#                               nn.Flatten(),\n",
        "#                               nn.Linear(in_features=in_features, out_features=hidden_layer),\n",
        "#                                nn.ReLU(),\n",
        "#                                nn.Linear(in_features=hidden_layer, out_features=out_features),\n",
        "#                                )\n",
        "#   def forward(self, x):\n",
        "#     return self.layer(x)\n",
        "# model = FashionNN(3*32*32, NUM_CLASSES)\n",
        "\n",
        "class ConvNN(nn.Module):\n",
        "  def __init__(self, in_channels=3, out_channels=NUM_CLASSES, hidden_channels=10):\n",
        "    super().__init__()\n",
        "    self.conv_block1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3, padding=0, stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.conv_block2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=0, stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "    )\n",
        "\n",
        "\n",
        "    self.fcnn = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(6*6*32, out_channels)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block1(x)\n",
        "    x = self.conv_block2(x)\n",
        "    x = self.fcnn(x)\n",
        "    return x\n",
        "\n",
        "model = ConvNN(in_channels=3, out_channels=NUM_CLASSES)"
      ],
      "metadata": {
        "id": "aWHbdcZM9x0B"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_tensor = torch.rand(10,3,32,32)\n",
        "result_tensor = model(rand_tensor)\n",
        "print(f\"shape of result tensor are: {result_tensor.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIy47vATOlGW",
        "outputId": "7b6dfbd0-2bfa-4a74-a1a1-1c8ebe2f2543"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of result tensor are: torch.Size([10, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#build loss function and optimizer"
      ],
      "metadata": {
        "id": "HZTgnFuPJFUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"
      ],
      "metadata": {
        "id": "aHWbGNf8JJEM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#build different def function(acc, train step, test step)"
      ],
      "metadata": {
        "id": "ArrSyjQ7IZRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def acc_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct/ len(y_true))*100.0\n",
        "  return acc\n",
        "\n",
        "def train_step(model, training_dataloader, loss_fn, optimizer, device):\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  model.train()\n",
        "  for batch_idx, item in enumerate(training_dataloader):\n",
        "    X_batch, y_batch = item\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    model.to(device)\n",
        "    logits = model(X_batch)\n",
        "    training_loss = loss_fn(logits, y_batch)\n",
        "    train_loss += training_loss\n",
        "    y_preds = torch.softmax(logits, dim=1).argmax(dim=1)\n",
        "    training_acc = acc_fn(y_batch, y_preds)\n",
        "    train_acc+=training_acc\n",
        "    optimizer.zero_grad()\n",
        "    training_loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f\"My training loss: {train_loss/len(training_dataloader)} Training acc:{train_acc/len(training_dataloader)}\")\n",
        "\n",
        "\n",
        "def test_step(model, testing_dataloader, loss_fn, device):\n",
        "  test_loss = 0\n",
        "  test_acc  = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, item in enumerate(testing_dataloader):\n",
        "      X_batch, y_batch = item\n",
        "      X_batch = X_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "      model.to(device)\n",
        "      logits = model(X_batch)\n",
        "      testing_loss = loss_fn(logits, y_batch)\n",
        "      test_loss += testing_loss\n",
        "      y_preds = torch.softmax(logits, dim=1).argmax(dim=1)\n",
        "      testing_acc = acc_fn(y_batch, y_preds)\n",
        "      test_acc+=testing_acc\n",
        "  print(f\"My testing loss: {test_loss/len(testing_dataloader)} Training acc:{test_acc/len(testing_dataloader)}\")"
      ],
      "metadata": {
        "id": "OsSTkW57ITtQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#train the model"
      ],
      "metadata": {
        "id": "cbSUp6xuIyNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "epochs = 500\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"My epoch {epoch}\\n-----------\")\n",
        "  train_step(model, train_data_loader, loss_fn, optimizer, device)\n",
        "  test_step(model, test_data_loader, loss_fn, device)\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "12c8070535de4ca28e2547de0b6c5980",
            "965a06c8ef6d4a03be3e9e27878bebd6",
            "4c7079c670bf4ccbb9107ea1d4a75d70",
            "b7b9f185a26e413e821d87df78112578",
            "09ba7d59586a40659a2c910d11581f78",
            "1a880ee40f364ea4b9530202b160cd74",
            "dd29213d0d61431aae17b7e5544f4ff3",
            "35951615392449c49341cbc8e00a2439",
            "443ef57959b34fbbb97b0f2f91b8003e",
            "9a60a4460ccc44adb69d3f5701a44e7f",
            "2689f2614f9c44cda41bc28543b5bbed"
          ]
        },
        "id": "oH8PLlKfI1C8",
        "outputId": "b956493f-9ff7-4394-9fef-c8447dbcafed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12c8070535de4ca28e2547de0b6c5980"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My epoch 0\n",
            "-----------\n",
            "My training loss: 1.381996989250183 Training acc:28.75\n",
            "My testing loss: 1.3863052129745483 Training acc:18.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 1\n",
            "-----------\n",
            "My training loss: 1.3595134019851685 Training acc:31.25\n",
            "My testing loss: 1.3886258602142334 Training acc:18.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 2\n",
            "-----------\n",
            "My training loss: 1.3331667184829712 Training acc:35.0\n",
            "My testing loss: 1.3861875534057617 Training acc:18.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 3\n",
            "-----------\n",
            "My training loss: 1.3149670362472534 Training acc:36.25\n",
            "My testing loss: 1.386887788772583 Training acc:18.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 4\n",
            "-----------\n",
            "My training loss: 1.3009049892425537 Training acc:36.25\n",
            "My testing loss: 1.3912020921707153 Training acc:18.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 5\n",
            "-----------\n",
            "My training loss: 1.2983735799789429 Training acc:32.5\n",
            "My testing loss: 1.4013195037841797 Training acc:18.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 6\n",
            "-----------\n",
            "My training loss: 1.2699236869812012 Training acc:36.25\n",
            "My testing loss: 1.4055657386779785 Training acc:18.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 7\n",
            "-----------\n",
            "My training loss: 1.2590070962905884 Training acc:40.0\n",
            "My testing loss: 1.415266990661621 Training acc:18.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 8\n",
            "-----------\n",
            "My training loss: 1.2773170471191406 Training acc:36.25\n",
            "My testing loss: 1.418825387954712 Training acc:18.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 9\n",
            "-----------\n",
            "My training loss: 1.256980538368225 Training acc:32.5\n",
            "My testing loss: 1.4177693128585815 Training acc:31.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 10\n",
            "-----------\n",
            "My training loss: 1.2576110363006592 Training acc:33.75\n",
            "My testing loss: 1.4141077995300293 Training acc:31.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 11\n",
            "-----------\n",
            "My training loss: 1.2411893606185913 Training acc:40.0\n",
            "My testing loss: 1.3949401378631592 Training acc:31.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 12\n",
            "-----------\n",
            "My training loss: 1.2234230041503906 Training acc:52.5\n",
            "My testing loss: 1.388627052307129 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 13\n",
            "-----------\n",
            "My training loss: 1.2149327993392944 Training acc:58.75\n",
            "My testing loss: 1.3901488780975342 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 14\n",
            "-----------\n",
            "My training loss: 1.217800498008728 Training acc:56.25\n",
            "My testing loss: 1.3880622386932373 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 15\n",
            "-----------\n",
            "My training loss: 1.2447279691696167 Training acc:55.0\n",
            "My testing loss: 1.3732281923294067 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 16\n",
            "-----------\n",
            "My training loss: 1.1952241659164429 Training acc:58.75\n",
            "My testing loss: 1.3582336902618408 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 17\n",
            "-----------\n",
            "My training loss: 1.2092303037643433 Training acc:55.0\n",
            "My testing loss: 1.3631107807159424 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 18\n",
            "-----------\n",
            "My training loss: 1.1625723838806152 Training acc:60.0\n",
            "My testing loss: 1.3661375045776367 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 19\n",
            "-----------\n",
            "My training loss: 1.1659531593322754 Training acc:55.0\n",
            "My testing loss: 1.3608251810073853 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 20\n",
            "-----------\n",
            "My training loss: 1.1450692415237427 Training acc:61.25\n",
            "My testing loss: 1.343743920326233 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 21\n",
            "-----------\n",
            "My training loss: 1.145792007446289 Training acc:56.25\n",
            "My testing loss: 1.3484902381896973 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 22\n",
            "-----------\n",
            "My training loss: 1.1629914045333862 Training acc:55.0\n",
            "My testing loss: 1.3439249992370605 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 23\n",
            "-----------\n",
            "My training loss: 1.1133426427841187 Training acc:60.0\n",
            "My testing loss: 1.3341844081878662 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 24\n",
            "-----------\n",
            "My training loss: 1.1529983282089233 Training acc:55.0\n",
            "My testing loss: 1.3405537605285645 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 25\n",
            "-----------\n",
            "My training loss: 1.1251152753829956 Training acc:57.5\n",
            "My testing loss: 1.3230712413787842 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 26\n",
            "-----------\n",
            "My training loss: 1.0892142057418823 Training acc:60.0\n",
            "My testing loss: 1.31614351272583 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 27\n",
            "-----------\n",
            "My training loss: 1.0908851623535156 Training acc:60.0\n",
            "My testing loss: 1.3125827312469482 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 28\n",
            "-----------\n",
            "My training loss: 1.0541738271713257 Training acc:65.0\n",
            "My testing loss: 1.300095558166504 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 29\n",
            "-----------\n",
            "My training loss: 1.0586000680923462 Training acc:61.25\n",
            "My testing loss: 1.2995071411132812 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 30\n",
            "-----------\n",
            "My training loss: 1.0440394878387451 Training acc:61.25\n",
            "My testing loss: 1.3002371788024902 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 31\n",
            "-----------\n",
            "My training loss: 1.0649350881576538 Training acc:63.75\n",
            "My testing loss: 1.2953438758850098 Training acc:37.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 32\n",
            "-----------\n",
            "My training loss: 1.0589745044708252 Training acc:63.75\n",
            "My testing loss: 1.2821564674377441 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 33\n",
            "-----------\n",
            "My training loss: 1.0411332845687866 Training acc:61.25\n",
            "My testing loss: 1.2631196975708008 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 34\n",
            "-----------\n",
            "My training loss: 1.0041544437408447 Training acc:61.25\n",
            "My testing loss: 1.2579141855239868 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 35\n",
            "-----------\n",
            "My training loss: 1.0092381238937378 Training acc:61.25\n",
            "My testing loss: 1.2601237297058105 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 36\n",
            "-----------\n",
            "My training loss: 1.0186964273452759 Training acc:62.5\n",
            "My testing loss: 1.2494416236877441 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 37\n",
            "-----------\n",
            "My training loss: 0.9831964373588562 Training acc:62.5\n",
            "My testing loss: 1.242775321006775 Training acc:37.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 38\n",
            "-----------\n",
            "My training loss: 0.9594818353652954 Training acc:65.0\n",
            "My testing loss: 1.2424427270889282 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 39\n",
            "-----------\n",
            "My training loss: 0.9913391470909119 Training acc:57.5\n",
            "My testing loss: 1.2450556755065918 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 40\n",
            "-----------\n",
            "My training loss: 0.9685199856758118 Training acc:62.5\n",
            "My testing loss: 1.2337708473205566 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 41\n",
            "-----------\n",
            "My training loss: 0.9379679560661316 Training acc:63.75\n",
            "My testing loss: 1.2273119688034058 Training acc:37.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 42\n",
            "-----------\n",
            "My training loss: 0.9931816458702087 Training acc:60.0\n",
            "My testing loss: 1.2226755619049072 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 43\n",
            "-----------\n",
            "My training loss: 0.9391170740127563 Training acc:63.75\n",
            "My testing loss: 1.2070872783660889 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 44\n",
            "-----------\n",
            "My training loss: 0.9169123768806458 Training acc:63.75\n",
            "My testing loss: 1.1981008052825928 Training acc:43.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 45\n",
            "-----------\n",
            "My training loss: 0.9004178047180176 Training acc:63.75\n",
            "My testing loss: 1.1930755376815796 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 46\n",
            "-----------\n",
            "My training loss: 0.9027050137519836 Training acc:63.75\n",
            "My testing loss: 1.1956425905227661 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 47\n",
            "-----------\n",
            "My training loss: 0.9145663380622864 Training acc:63.75\n",
            "My testing loss: 1.1858707666397095 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 48\n",
            "-----------\n",
            "My training loss: 0.8695291876792908 Training acc:67.5\n",
            "My testing loss: 1.1791588068008423 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 49\n",
            "-----------\n",
            "My training loss: 0.8704678416252136 Training acc:67.5\n",
            "My testing loss: 1.180359125137329 Training acc:37.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 50\n",
            "-----------\n",
            "My training loss: 0.8452838063240051 Training acc:66.25\n",
            "My testing loss: 1.1801159381866455 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 51\n",
            "-----------\n",
            "My training loss: 0.8200984001159668 Training acc:65.0\n",
            "My testing loss: 1.181149959564209 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 52\n",
            "-----------\n",
            "My training loss: 0.8513489961624146 Training acc:63.75\n",
            "My testing loss: 1.178987979888916 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 53\n",
            "-----------\n",
            "My training loss: 0.847819447517395 Training acc:62.5\n",
            "My testing loss: 1.1755928993225098 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 54\n",
            "-----------\n",
            "My training loss: 0.8546748161315918 Training acc:62.5\n",
            "My testing loss: 1.1688768863677979 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 55\n",
            "-----------\n",
            "My training loss: 0.8055834770202637 Training acc:67.5\n",
            "My testing loss: 1.1697160005569458 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 56\n",
            "-----------\n",
            "My training loss: 0.8113101124763489 Training acc:67.5\n",
            "My testing loss: 1.1627564430236816 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 57\n",
            "-----------\n",
            "My training loss: 0.8148841261863708 Training acc:63.75\n",
            "My testing loss: 1.1610102653503418 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 58\n",
            "-----------\n",
            "My training loss: 0.8882001042366028 Training acc:58.75\n",
            "My testing loss: 1.1510779857635498 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 59\n",
            "-----------\n",
            "My training loss: 0.8010309338569641 Training acc:70.0\n",
            "My testing loss: 1.132117748260498 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 60\n",
            "-----------\n",
            "My training loss: 0.7896497845649719 Training acc:70.0\n",
            "My testing loss: 1.1322667598724365 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 61\n",
            "-----------\n",
            "My training loss: 0.7676482200622559 Training acc:70.0\n",
            "My testing loss: 1.1304423809051514 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 62\n",
            "-----------\n",
            "My training loss: 0.9669758677482605 Training acc:62.5\n",
            "My testing loss: 1.125850796699524 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 63\n",
            "-----------\n",
            "My training loss: 0.7862836718559265 Training acc:72.5\n",
            "My testing loss: 1.1247960329055786 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 64\n",
            "-----------\n",
            "My training loss: 0.8252508044242859 Training acc:71.25\n",
            "My testing loss: 1.1194725036621094 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 65\n",
            "-----------\n",
            "My training loss: 0.7969821095466614 Training acc:70.0\n",
            "My testing loss: 1.0970640182495117 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 66\n",
            "-----------\n",
            "My training loss: 0.7589989304542542 Training acc:71.25\n",
            "My testing loss: 1.1001852750778198 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 67\n",
            "-----------\n",
            "My training loss: 0.7710351347923279 Training acc:72.5\n",
            "My testing loss: 1.0973665714263916 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 68\n",
            "-----------\n",
            "My training loss: 0.7353692650794983 Training acc:72.5\n",
            "My testing loss: 1.0916037559509277 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 69\n",
            "-----------\n",
            "My training loss: 0.928763210773468 Training acc:67.5\n",
            "My testing loss: 1.0865042209625244 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 70\n",
            "-----------\n",
            "My training loss: 0.7389602065086365 Training acc:73.75\n",
            "My testing loss: 1.085517168045044 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 71\n",
            "-----------\n",
            "My training loss: 0.7821890711784363 Training acc:67.5\n",
            "My testing loss: 1.0802297592163086 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 72\n",
            "-----------\n",
            "My training loss: 0.7549961805343628 Training acc:72.5\n",
            "My testing loss: 1.0712686777114868 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 73\n",
            "-----------\n",
            "My training loss: 0.7422727942466736 Training acc:71.25\n",
            "My testing loss: 1.071108102798462 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 74\n",
            "-----------\n",
            "My training loss: 0.7423620223999023 Training acc:71.25\n",
            "My testing loss: 1.0658525228500366 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 75\n",
            "-----------\n",
            "My training loss: 0.7843949794769287 Training acc:68.75\n",
            "My testing loss: 1.06168794631958 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 76\n",
            "-----------\n",
            "My training loss: 0.7434762120246887 Training acc:72.5\n",
            "My testing loss: 1.059314250946045 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 77\n",
            "-----------\n",
            "My training loss: 0.7355577945709229 Training acc:71.25\n",
            "My testing loss: 1.0669074058532715 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 78\n",
            "-----------\n",
            "My training loss: 0.7947403192520142 Training acc:67.5\n",
            "My testing loss: 1.0620620250701904 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 79\n",
            "-----------\n",
            "My training loss: 0.7386932969093323 Training acc:68.75\n",
            "My testing loss: 1.0511696338653564 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 80\n",
            "-----------\n",
            "My training loss: 0.7599935531616211 Training acc:68.75\n",
            "My testing loss: 1.0491348505020142 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 81\n",
            "-----------\n",
            "My training loss: 0.8256384134292603 Training acc:66.25\n",
            "My testing loss: 1.0408728122711182 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 82\n",
            "-----------\n",
            "My training loss: 0.7191027998924255 Training acc:72.5\n",
            "My testing loss: 1.0258886814117432 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 83\n",
            "-----------\n",
            "My training loss: 0.6955659985542297 Training acc:72.5\n",
            "My testing loss: 1.0246106386184692 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 84\n",
            "-----------\n",
            "My training loss: 0.7234561443328857 Training acc:75.0\n",
            "My testing loss: 1.0196030139923096 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 85\n",
            "-----------\n",
            "My training loss: 0.7421454787254333 Training acc:68.75\n",
            "My testing loss: 1.016261100769043 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 86\n",
            "-----------\n",
            "My training loss: 0.7478283047676086 Training acc:71.25\n",
            "My testing loss: 1.0116171836853027 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 87\n",
            "-----------\n",
            "My training loss: 0.7607280611991882 Training acc:66.25\n",
            "My testing loss: 1.0225746631622314 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 88\n",
            "-----------\n",
            "My training loss: 0.7895218133926392 Training acc:68.75\n",
            "My testing loss: 1.0190342664718628 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 89\n",
            "-----------\n",
            "My training loss: 0.7700897455215454 Training acc:73.75\n",
            "My testing loss: 1.0201096534729004 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 90\n",
            "-----------\n",
            "My training loss: 0.6967139840126038 Training acc:75.0\n",
            "My testing loss: 1.0136022567749023 Training acc:50.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 91\n",
            "-----------\n",
            "My training loss: 0.7439510822296143 Training acc:72.5\n",
            "My testing loss: 1.0055288076400757 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 92\n",
            "-----------\n",
            "My training loss: 0.7384876608848572 Training acc:70.0\n",
            "My testing loss: 1.0081517696380615 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 93\n",
            "-----------\n",
            "My training loss: 0.710852324962616 Training acc:68.75\n",
            "My testing loss: 1.0001933574676514 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 94\n",
            "-----------\n",
            "My training loss: 0.7308365702629089 Training acc:72.5\n",
            "My testing loss: 0.9992262125015259 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 95\n",
            "-----------\n",
            "My training loss: 0.6947692632675171 Training acc:76.25\n",
            "My testing loss: 0.9895381331443787 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 96\n",
            "-----------\n",
            "My training loss: 0.6674022078514099 Training acc:75.0\n",
            "My testing loss: 0.9960535764694214 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 97\n",
            "-----------\n",
            "My training loss: 0.7719890475273132 Training acc:66.25\n",
            "My testing loss: 0.9936169385910034 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 98\n",
            "-----------\n",
            "My training loss: 0.6716460585594177 Training acc:72.5\n",
            "My testing loss: 0.9937970042228699 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 99\n",
            "-----------\n",
            "My training loss: 0.68939608335495 Training acc:71.25\n",
            "My testing loss: 0.9870898127555847 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 100\n",
            "-----------\n",
            "My training loss: 0.6720296144485474 Training acc:75.0\n",
            "My testing loss: 0.9876351356506348 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 101\n",
            "-----------\n",
            "My training loss: 0.7502610087394714 Training acc:72.5\n",
            "My testing loss: 0.9860258102416992 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 102\n",
            "-----------\n",
            "My training loss: 0.7400206923484802 Training acc:73.75\n",
            "My testing loss: 0.9781131744384766 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 103\n",
            "-----------\n",
            "My training loss: 0.6565970182418823 Training acc:76.25\n",
            "My testing loss: 0.9773167967796326 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 104\n",
            "-----------\n",
            "My training loss: 0.7272829413414001 Training acc:73.75\n",
            "My testing loss: 0.9690343737602234 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 105\n",
            "-----------\n",
            "My training loss: 0.6761253476142883 Training acc:75.0\n",
            "My testing loss: 0.9699758291244507 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 106\n",
            "-----------\n",
            "My training loss: 0.6690779328346252 Training acc:75.0\n",
            "My testing loss: 0.9706651568412781 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 107\n",
            "-----------\n",
            "My training loss: 0.6464754939079285 Training acc:75.0\n",
            "My testing loss: 0.9705514907836914 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 108\n",
            "-----------\n",
            "My training loss: 0.6437851786613464 Training acc:73.75\n",
            "My testing loss: 0.9667838215827942 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 109\n",
            "-----------\n",
            "My training loss: 0.6901201605796814 Training acc:71.25\n",
            "My testing loss: 0.9644930362701416 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 110\n",
            "-----------\n",
            "My training loss: 0.7096481919288635 Training acc:71.25\n",
            "My testing loss: 0.9587689638137817 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 111\n",
            "-----------\n",
            "My training loss: 0.6331539154052734 Training acc:75.0\n",
            "My testing loss: 0.9573474526405334 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 112\n",
            "-----------\n",
            "My training loss: 0.6653574705123901 Training acc:72.5\n",
            "My testing loss: 0.9604931473731995 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 113\n",
            "-----------\n",
            "My training loss: 0.8670773506164551 Training acc:68.75\n",
            "My testing loss: 0.9529097080230713 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 114\n",
            "-----------\n",
            "My training loss: 0.6517952084541321 Training acc:75.0\n",
            "My testing loss: 0.9439020156860352 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 115\n",
            "-----------\n",
            "My training loss: 0.6361206769943237 Training acc:75.0\n",
            "My testing loss: 0.9381298422813416 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 116\n",
            "-----------\n",
            "My training loss: 0.6201035976409912 Training acc:75.0\n",
            "My testing loss: 0.9337700009346008 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 117\n",
            "-----------\n",
            "My training loss: 0.6197512149810791 Training acc:76.25\n",
            "My testing loss: 0.9325782060623169 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 118\n",
            "-----------\n",
            "My training loss: 0.6277325749397278 Training acc:76.25\n",
            "My testing loss: 0.9360092282295227 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 119\n",
            "-----------\n",
            "My training loss: 0.6186150908470154 Training acc:76.25\n",
            "My testing loss: 0.9340683221817017 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 120\n",
            "-----------\n",
            "My training loss: 0.6504247188568115 Training acc:71.25\n",
            "My testing loss: 0.9303433895111084 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 121\n",
            "-----------\n",
            "My training loss: 0.605408787727356 Training acc:76.25\n",
            "My testing loss: 0.9296162128448486 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 122\n",
            "-----------\n",
            "My training loss: 0.6272510886192322 Training acc:77.5\n",
            "My testing loss: 0.9289265871047974 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 123\n",
            "-----------\n",
            "My training loss: 0.6259104609489441 Training acc:77.5\n",
            "My testing loss: 0.9258387684822083 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 124\n",
            "-----------\n",
            "My training loss: 0.6269009709358215 Training acc:76.25\n",
            "My testing loss: 0.9325252771377563 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 125\n",
            "-----------\n",
            "My training loss: 0.6443901062011719 Training acc:72.5\n",
            "My testing loss: 0.9216887950897217 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 126\n",
            "-----------\n",
            "My training loss: 0.621739387512207 Training acc:78.75\n",
            "My testing loss: 0.9204950332641602 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 127\n",
            "-----------\n",
            "My training loss: 0.6222852468490601 Training acc:78.75\n",
            "My testing loss: 0.9172895550727844 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 128\n",
            "-----------\n",
            "My training loss: 0.6045855283737183 Training acc:77.5\n",
            "My testing loss: 0.9149115085601807 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 129\n",
            "-----------\n",
            "My training loss: 0.5890747904777527 Training acc:77.5\n",
            "My testing loss: 0.9176269173622131 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 130\n",
            "-----------\n",
            "My training loss: 0.5963916182518005 Training acc:75.0\n",
            "My testing loss: 0.9164096117019653 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 131\n",
            "-----------\n",
            "My training loss: 0.6513041853904724 Training acc:72.5\n",
            "My testing loss: 0.9140519499778748 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 132\n",
            "-----------\n",
            "My training loss: 0.6204516291618347 Training acc:75.0\n",
            "My testing loss: 0.9141091108322144 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 133\n",
            "-----------\n",
            "My training loss: 0.640785813331604 Training acc:72.5\n",
            "My testing loss: 0.9075144529342651 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 134\n",
            "-----------\n",
            "My training loss: 0.6373831629753113 Training acc:73.75\n",
            "My testing loss: 0.903279185295105 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 135\n",
            "-----------\n",
            "My training loss: 0.5864655375480652 Training acc:77.5\n",
            "My testing loss: 0.9098637700080872 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 136\n",
            "-----------\n",
            "My training loss: 0.6061450839042664 Training acc:76.25\n",
            "My testing loss: 0.9083722829818726 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 137\n",
            "-----------\n",
            "My training loss: 0.5775047540664673 Training acc:75.0\n",
            "My testing loss: 0.9044056534767151 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 138\n",
            "-----------\n",
            "My training loss: 0.6132926344871521 Training acc:77.5\n",
            "My testing loss: 0.9045581817626953 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 139\n",
            "-----------\n",
            "My training loss: 0.5845677256584167 Training acc:77.5\n",
            "My testing loss: 0.9028372764587402 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 140\n",
            "-----------\n",
            "My training loss: 0.6248895525932312 Training acc:73.75\n",
            "My testing loss: 0.8971126079559326 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 141\n",
            "-----------\n",
            "My training loss: 0.5843879580497742 Training acc:77.5\n",
            "My testing loss: 0.8949649333953857 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 142\n",
            "-----------\n",
            "My training loss: 0.6509420871734619 Training acc:72.5\n",
            "My testing loss: 0.8900638818740845 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 143\n",
            "-----------\n",
            "My training loss: 0.6142313480377197 Training acc:73.75\n",
            "My testing loss: 0.8862501382827759 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 144\n",
            "-----------\n",
            "My training loss: 0.5934343338012695 Training acc:80.0\n",
            "My testing loss: 0.8857471942901611 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 145\n",
            "-----------\n",
            "My training loss: 0.5779985785484314 Training acc:80.0\n",
            "My testing loss: 0.8819860219955444 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 146\n",
            "-----------\n",
            "My training loss: 0.6002992391586304 Training acc:75.0\n",
            "My testing loss: 0.8817694187164307 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 147\n",
            "-----------\n",
            "My training loss: 0.5848472714424133 Training acc:77.5\n",
            "My testing loss: 0.8980649709701538 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 148\n",
            "-----------\n",
            "My training loss: 0.615312397480011 Training acc:76.25\n",
            "My testing loss: 0.8861854076385498 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 149\n",
            "-----------\n",
            "My training loss: 0.5901740193367004 Training acc:71.25\n",
            "My testing loss: 0.8813024759292603 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 150\n",
            "-----------\n",
            "My training loss: 0.5686177611351013 Training acc:80.0\n",
            "My testing loss: 0.8830125331878662 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 151\n",
            "-----------\n",
            "My training loss: 0.5854061245918274 Training acc:76.25\n",
            "My testing loss: 0.8799115419387817 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 152\n",
            "-----------\n",
            "My training loss: 0.5906508564949036 Training acc:78.75\n",
            "My testing loss: 0.8745719790458679 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 153\n",
            "-----------\n",
            "My training loss: 0.554972231388092 Training acc:81.25\n",
            "My testing loss: 0.875229001045227 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 154\n",
            "-----------\n",
            "My training loss: 0.5588561296463013 Training acc:81.25\n",
            "My testing loss: 0.8728265166282654 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 155\n",
            "-----------\n",
            "My training loss: 0.5586606860160828 Training acc:80.0\n",
            "My testing loss: 0.8712661862373352 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 156\n",
            "-----------\n",
            "My training loss: 0.5654565691947937 Training acc:76.25\n",
            "My testing loss: 0.8693827390670776 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 157\n",
            "-----------\n",
            "My training loss: 0.604702889919281 Training acc:75.0\n",
            "My testing loss: 0.8709721565246582 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 158\n",
            "-----------\n",
            "My training loss: 0.5860949158668518 Training acc:72.5\n",
            "My testing loss: 0.8692053556442261 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 159\n",
            "-----------\n",
            "My training loss: 0.5567865371704102 Training acc:76.25\n",
            "My testing loss: 0.8662987351417542 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 160\n",
            "-----------\n",
            "My training loss: 0.5519121885299683 Training acc:78.75\n",
            "My testing loss: 0.8684118986129761 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 161\n",
            "-----------\n",
            "My training loss: 0.6226800084114075 Training acc:77.5\n",
            "My testing loss: 0.8659449815750122 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 162\n",
            "-----------\n",
            "My training loss: 0.5421629548072815 Training acc:81.25\n",
            "My testing loss: 0.8684924840927124 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 163\n",
            "-----------\n",
            "My training loss: 0.5783238410949707 Training acc:75.0\n",
            "My testing loss: 0.8686358332633972 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 164\n",
            "-----------\n",
            "My training loss: 0.5545971989631653 Training acc:81.25\n",
            "My testing loss: 0.8649333119392395 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 165\n",
            "-----------\n",
            "My training loss: 0.5789288878440857 Training acc:77.5\n",
            "My testing loss: 0.856850266456604 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 166\n",
            "-----------\n",
            "My training loss: 0.5751314759254456 Training acc:80.0\n",
            "My testing loss: 0.855171263217926 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 167\n",
            "-----------\n",
            "My training loss: 0.5295007824897766 Training acc:82.5\n",
            "My testing loss: 0.8574503660202026 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 168\n",
            "-----------\n",
            "My training loss: 0.6183522343635559 Training acc:78.75\n",
            "My testing loss: 0.8517034649848938 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 169\n",
            "-----------\n",
            "My training loss: 0.5396191477775574 Training acc:81.25\n",
            "My testing loss: 0.8512070178985596 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 170\n",
            "-----------\n",
            "My training loss: 0.5584253668785095 Training acc:81.25\n",
            "My testing loss: 0.8403455018997192 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 171\n",
            "-----------\n",
            "My training loss: 0.5595851540565491 Training acc:76.25\n",
            "My testing loss: 0.8405642509460449 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 172\n",
            "-----------\n",
            "My training loss: 0.5373615026473999 Training acc:81.25\n",
            "My testing loss: 0.8385376930236816 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 173\n",
            "-----------\n",
            "My training loss: 0.5634860992431641 Training acc:82.5\n",
            "My testing loss: 0.8405727744102478 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 174\n",
            "-----------\n",
            "My training loss: 0.544726550579071 Training acc:82.5\n",
            "My testing loss: 0.8406790494918823 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 175\n",
            "-----------\n",
            "My training loss: 0.5827621817588806 Training acc:76.25\n",
            "My testing loss: 0.8363527059555054 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 176\n",
            "-----------\n",
            "My training loss: 0.5917593240737915 Training acc:77.5\n",
            "My testing loss: 0.8364381790161133 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 177\n",
            "-----------\n",
            "My training loss: 0.5525662899017334 Training acc:77.5\n",
            "My testing loss: 0.8357569575309753 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 178\n",
            "-----------\n",
            "My training loss: 0.5841273069381714 Training acc:77.5\n",
            "My testing loss: 0.8360952138900757 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 179\n",
            "-----------\n",
            "My training loss: 0.5214095115661621 Training acc:80.0\n",
            "My testing loss: 0.8360245227813721 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 180\n",
            "-----------\n",
            "My training loss: 0.5145280361175537 Training acc:80.0\n",
            "My testing loss: 0.8377387523651123 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 181\n",
            "-----------\n",
            "My training loss: 0.5177683234214783 Training acc:83.75\n",
            "My testing loss: 0.8386560082435608 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 182\n",
            "-----------\n",
            "My training loss: 0.545346200466156 Training acc:78.75\n",
            "My testing loss: 0.8358026742935181 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 183\n",
            "-----------\n",
            "My training loss: 0.5249740481376648 Training acc:81.25\n",
            "My testing loss: 0.8337529301643372 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 184\n",
            "-----------\n",
            "My training loss: 0.5489315390586853 Training acc:76.25\n",
            "My testing loss: 0.8392562866210938 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 185\n",
            "-----------\n",
            "My training loss: 0.5204541087150574 Training acc:83.75\n",
            "My testing loss: 0.8353159427642822 Training acc:56.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 186\n",
            "-----------\n",
            "My training loss: 0.5162524580955505 Training acc:82.5\n",
            "My testing loss: 0.8281862735748291 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 187\n",
            "-----------\n",
            "My training loss: 0.5099543333053589 Training acc:82.5\n",
            "My testing loss: 0.8264139890670776 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 188\n",
            "-----------\n",
            "My training loss: 0.5029562711715698 Training acc:82.5\n",
            "My testing loss: 0.8222015500068665 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 189\n",
            "-----------\n",
            "My training loss: 0.4925801455974579 Training acc:81.25\n",
            "My testing loss: 0.8209254741668701 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 190\n",
            "-----------\n",
            "My training loss: 0.5275140404701233 Training acc:78.75\n",
            "My testing loss: 0.8270530104637146 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 191\n",
            "-----------\n",
            "My training loss: 0.49640700221061707 Training acc:83.75\n",
            "My testing loss: 0.8286373615264893 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 192\n",
            "-----------\n",
            "My training loss: 0.530912458896637 Training acc:78.75\n",
            "My testing loss: 0.8186145424842834 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 193\n",
            "-----------\n",
            "My training loss: 0.5226027369499207 Training acc:85.0\n",
            "My testing loss: 0.8206766247749329 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 194\n",
            "-----------\n",
            "My training loss: 0.5357324481010437 Training acc:78.75\n",
            "My testing loss: 0.814397394657135 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 195\n",
            "-----------\n",
            "My training loss: 0.48951101303100586 Training acc:78.75\n",
            "My testing loss: 0.8153538107872009 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 196\n",
            "-----------\n",
            "My training loss: 0.5120102167129517 Training acc:81.25\n",
            "My testing loss: 0.8192965984344482 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 197\n",
            "-----------\n",
            "My training loss: 0.4984211027622223 Training acc:80.0\n",
            "My testing loss: 0.8114619255065918 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 198\n",
            "-----------\n",
            "My training loss: 0.5786421895027161 Training acc:78.75\n",
            "My testing loss: 0.8178324103355408 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 199\n",
            "-----------\n",
            "My training loss: 0.5110507011413574 Training acc:83.75\n",
            "My testing loss: 0.8175925612449646 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 200\n",
            "-----------\n",
            "My training loss: 0.5053727030754089 Training acc:81.25\n",
            "My testing loss: 0.8140196204185486 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 201\n",
            "-----------\n",
            "My training loss: 0.49949198961257935 Training acc:83.75\n",
            "My testing loss: 0.8154048323631287 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 202\n",
            "-----------\n",
            "My training loss: 0.49522730708122253 Training acc:82.5\n",
            "My testing loss: 0.8166722655296326 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 203\n",
            "-----------\n",
            "My training loss: 0.5053269267082214 Training acc:82.5\n",
            "My testing loss: 0.812462568283081 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 204\n",
            "-----------\n",
            "My training loss: 0.47078919410705566 Training acc:81.25\n",
            "My testing loss: 0.8140141367912292 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 205\n",
            "-----------\n",
            "My training loss: 0.49117311835289 Training acc:80.0\n",
            "My testing loss: 0.8072549104690552 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 206\n",
            "-----------\n",
            "My training loss: 0.5841896533966064 Training acc:81.25\n",
            "My testing loss: 0.8199194669723511 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 207\n",
            "-----------\n",
            "My training loss: 0.46450304985046387 Training acc:83.75\n",
            "My testing loss: 0.8204669952392578 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 208\n",
            "-----------\n",
            "My training loss: 0.5069266557693481 Training acc:81.25\n",
            "My testing loss: 0.808086633682251 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 209\n",
            "-----------\n",
            "My training loss: 0.5186893939971924 Training acc:81.25\n",
            "My testing loss: 0.8043391704559326 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 210\n",
            "-----------\n",
            "My training loss: 0.5067031979560852 Training acc:77.5\n",
            "My testing loss: 0.792153537273407 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 211\n",
            "-----------\n",
            "My training loss: 0.508396327495575 Training acc:78.75\n",
            "My testing loss: 0.7937647104263306 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 212\n",
            "-----------\n",
            "My training loss: 0.5257138013839722 Training acc:80.0\n",
            "My testing loss: 0.8021085858345032 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 213\n",
            "-----------\n",
            "My training loss: 0.5082493424415588 Training acc:81.25\n",
            "My testing loss: 0.7900710105895996 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 214\n",
            "-----------\n",
            "My training loss: 0.48522621393203735 Training acc:81.25\n",
            "My testing loss: 0.7872447371482849 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 215\n",
            "-----------\n",
            "My training loss: 0.4924881160259247 Training acc:80.0\n",
            "My testing loss: 0.7875771522521973 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 216\n",
            "-----------\n",
            "My training loss: 0.5825933218002319 Training acc:80.0\n",
            "My testing loss: 0.791510820388794 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 217\n",
            "-----------\n",
            "My training loss: 0.46540066599845886 Training acc:83.75\n",
            "My testing loss: 0.7859867811203003 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 218\n",
            "-----------\n",
            "My training loss: 0.46748432517051697 Training acc:85.0\n",
            "My testing loss: 0.7857688665390015 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 219\n",
            "-----------\n",
            "My training loss: 0.5486382842063904 Training acc:75.0\n",
            "My testing loss: 0.7785675525665283 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 220\n",
            "-----------\n",
            "My training loss: 0.47794467210769653 Training acc:85.0\n",
            "My testing loss: 0.7838566899299622 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 221\n",
            "-----------\n",
            "My training loss: 0.4892895817756653 Training acc:81.25\n",
            "My testing loss: 0.7756699323654175 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 222\n",
            "-----------\n",
            "My training loss: 0.48901328444480896 Training acc:77.5\n",
            "My testing loss: 0.7824528217315674 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 223\n",
            "-----------\n",
            "My training loss: 0.4601078927516937 Training acc:82.5\n",
            "My testing loss: 0.7934138774871826 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 224\n",
            "-----------\n",
            "My training loss: 0.45481014251708984 Training acc:85.0\n",
            "My testing loss: 0.7817137241363525 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 225\n",
            "-----------\n",
            "My training loss: 0.44067221879959106 Training acc:82.5\n",
            "My testing loss: 0.7778258919715881 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 226\n",
            "-----------\n",
            "My training loss: 0.4904559254646301 Training acc:80.0\n",
            "My testing loss: 0.7813482284545898 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 227\n",
            "-----------\n",
            "My training loss: 0.49186745285987854 Training acc:80.0\n",
            "My testing loss: 0.7796006202697754 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 228\n",
            "-----------\n",
            "My training loss: 0.44299712777137756 Training acc:85.0\n",
            "My testing loss: 0.7767758965492249 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 229\n",
            "-----------\n",
            "My training loss: 0.45152613520622253 Training acc:83.75\n",
            "My testing loss: 0.7793170809745789 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 230\n",
            "-----------\n",
            "My training loss: 0.45944175124168396 Training acc:85.0\n",
            "My testing loss: 0.7753244638442993 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 231\n",
            "-----------\n",
            "My training loss: 0.4719739854335785 Training acc:80.0\n",
            "My testing loss: 0.7718356847763062 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 232\n",
            "-----------\n",
            "My training loss: 0.4330827295780182 Training acc:82.5\n",
            "My testing loss: 0.7824454307556152 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 233\n",
            "-----------\n",
            "My training loss: 0.4368990957736969 Training acc:83.75\n",
            "My testing loss: 0.7759478092193604 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 234\n",
            "-----------\n",
            "My training loss: 0.4333994388580322 Training acc:83.75\n",
            "My testing loss: 0.7744432687759399 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 235\n",
            "-----------\n",
            "My training loss: 0.43088412284851074 Training acc:82.5\n",
            "My testing loss: 0.772446870803833 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 236\n",
            "-----------\n",
            "My training loss: 0.4409920871257782 Training acc:83.75\n",
            "My testing loss: 0.775979220867157 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 237\n",
            "-----------\n",
            "My training loss: 0.426931768655777 Training acc:83.75\n",
            "My testing loss: 0.7738680243492126 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 238\n",
            "-----------\n",
            "My training loss: 0.43046122789382935 Training acc:83.75\n",
            "My testing loss: 0.7677838206291199 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 239\n",
            "-----------\n",
            "My training loss: 0.43640899658203125 Training acc:82.5\n",
            "My testing loss: 0.7758437395095825 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 240\n",
            "-----------\n",
            "My training loss: 0.4428471624851227 Training acc:83.75\n",
            "My testing loss: 0.7726442813873291 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 241\n",
            "-----------\n",
            "My training loss: 0.4761168956756592 Training acc:78.75\n",
            "My testing loss: 0.7765538692474365 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 242\n",
            "-----------\n",
            "My training loss: 0.4357426166534424 Training acc:83.75\n",
            "My testing loss: 0.7810748815536499 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 243\n",
            "-----------\n",
            "My training loss: 0.42464205622673035 Training acc:83.75\n",
            "My testing loss: 0.7741987109184265 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 244\n",
            "-----------\n",
            "My training loss: 0.4132424294948578 Training acc:83.75\n",
            "My testing loss: 0.7729151248931885 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 245\n",
            "-----------\n",
            "My training loss: 0.41289693117141724 Training acc:82.5\n",
            "My testing loss: 0.7697054743766785 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 246\n",
            "-----------\n",
            "My training loss: 0.4326152801513672 Training acc:82.5\n",
            "My testing loss: 0.7668229341506958 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 247\n",
            "-----------\n",
            "My training loss: 0.4367623031139374 Training acc:83.75\n",
            "My testing loss: 0.7771915197372437 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 248\n",
            "-----------\n",
            "My training loss: 0.5023689270019531 Training acc:81.25\n",
            "My testing loss: 0.776222825050354 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 249\n",
            "-----------\n",
            "My training loss: 0.42493319511413574 Training acc:85.0\n",
            "My testing loss: 0.7785512804985046 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 250\n",
            "-----------\n",
            "My training loss: 0.42001014947891235 Training acc:83.75\n",
            "My testing loss: 0.7643656730651855 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 251\n",
            "-----------\n",
            "My training loss: 0.42390164732933044 Training acc:85.0\n",
            "My testing loss: 0.7627233266830444 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 252\n",
            "-----------\n",
            "My training loss: 0.4562462866306305 Training acc:78.75\n",
            "My testing loss: 0.756767213344574 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 253\n",
            "-----------\n",
            "My training loss: 0.40850263833999634 Training acc:83.75\n",
            "My testing loss: 0.760118305683136 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 254\n",
            "-----------\n",
            "My training loss: 0.41335129737854004 Training acc:85.0\n",
            "My testing loss: 0.7620553970336914 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 255\n",
            "-----------\n",
            "My training loss: 0.40896597504615784 Training acc:85.0\n",
            "My testing loss: 0.7723865509033203 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 256\n",
            "-----------\n",
            "My training loss: 0.4063621163368225 Training acc:86.25\n",
            "My testing loss: 0.7675447463989258 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 257\n",
            "-----------\n",
            "My training loss: 0.46393662691116333 Training acc:80.0\n",
            "My testing loss: 0.7621347308158875 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 258\n",
            "-----------\n",
            "My training loss: 0.4065786302089691 Training acc:85.0\n",
            "My testing loss: 0.7725021243095398 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 259\n",
            "-----------\n",
            "My training loss: 0.40445050597190857 Training acc:85.0\n",
            "My testing loss: 0.7748297452926636 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 260\n",
            "-----------\n",
            "My training loss: 0.41341257095336914 Training acc:86.25\n",
            "My testing loss: 0.7734602689743042 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 261\n",
            "-----------\n",
            "My training loss: 0.4202134311199188 Training acc:85.0\n",
            "My testing loss: 0.7649911046028137 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 262\n",
            "-----------\n",
            "My training loss: 0.42420411109924316 Training acc:83.75\n",
            "My testing loss: 0.7654927372932434 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 263\n",
            "-----------\n",
            "My training loss: 0.38953885436058044 Training acc:85.0\n",
            "My testing loss: 0.7689281105995178 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 264\n",
            "-----------\n",
            "My training loss: 0.4299928843975067 Training acc:81.25\n",
            "My testing loss: 0.7742500305175781 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 265\n",
            "-----------\n",
            "My training loss: 0.39581385254859924 Training acc:86.25\n",
            "My testing loss: 0.780264139175415 Training acc:62.5\n",
            "\n",
            "\n",
            "\n",
            "My epoch 266\n",
            "-----------\n",
            "My training loss: 0.40918269753456116 Training acc:85.0\n",
            "My testing loss: 0.7667826414108276 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 267\n",
            "-----------\n",
            "My training loss: 0.39204496145248413 Training acc:85.0\n",
            "My testing loss: 0.7673357725143433 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 268\n",
            "-----------\n",
            "My training loss: 0.3964090347290039 Training acc:85.0\n",
            "My testing loss: 0.7726314067840576 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 269\n",
            "-----------\n",
            "My training loss: 0.388889878988266 Training acc:85.0\n",
            "My testing loss: 0.7758837938308716 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 270\n",
            "-----------\n",
            "My training loss: 0.43403559923171997 Training acc:81.25\n",
            "My testing loss: 0.7678335309028625 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 271\n",
            "-----------\n",
            "My training loss: 0.3809177577495575 Training acc:85.0\n",
            "My testing loss: 0.7683755159378052 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 272\n",
            "-----------\n",
            "My training loss: 0.42966824769973755 Training acc:80.0\n",
            "My testing loss: 0.7707489132881165 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 273\n",
            "-----------\n",
            "My training loss: 0.3802054524421692 Training acc:87.5\n",
            "My testing loss: 0.7849413752555847 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 274\n",
            "-----------\n",
            "My training loss: 0.4065551459789276 Training acc:85.0\n",
            "My testing loss: 0.7730200290679932 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 275\n",
            "-----------\n",
            "My training loss: 0.40949830412864685 Training acc:83.75\n",
            "My testing loss: 0.7769944667816162 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 276\n",
            "-----------\n",
            "My training loss: 0.38662266731262207 Training acc:86.25\n",
            "My testing loss: 0.7715562582015991 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 277\n",
            "-----------\n",
            "My training loss: 0.4288989007472992 Training acc:80.0\n",
            "My testing loss: 0.7716891765594482 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 278\n",
            "-----------\n",
            "My training loss: 0.3984903395175934 Training acc:85.0\n",
            "My testing loss: 0.7622191905975342 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 279\n",
            "-----------\n",
            "My training loss: 0.40084168314933777 Training acc:85.0\n",
            "My testing loss: 0.7643988132476807 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 280\n",
            "-----------\n",
            "My training loss: 0.42199641466140747 Training acc:81.25\n",
            "My testing loss: 0.7726787328720093 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 281\n",
            "-----------\n",
            "My training loss: 0.385017067193985 Training acc:85.0\n",
            "My testing loss: 0.7826395630836487 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 282\n",
            "-----------\n",
            "My training loss: 0.382037490606308 Training acc:87.5\n",
            "My testing loss: 0.7684175968170166 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 283\n",
            "-----------\n",
            "My training loss: 0.3845459818840027 Training acc:85.0\n",
            "My testing loss: 0.7661625742912292 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 284\n",
            "-----------\n",
            "My training loss: 0.4036124348640442 Training acc:86.25\n",
            "My testing loss: 0.7700582146644592 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 285\n",
            "-----------\n",
            "My training loss: 0.3712429404258728 Training acc:85.0\n",
            "My testing loss: 0.7743330597877502 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 286\n",
            "-----------\n",
            "My training loss: 0.3887794613838196 Training acc:85.0\n",
            "My testing loss: 0.7631754875183105 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 287\n",
            "-----------\n",
            "My training loss: 0.3585631251335144 Training acc:85.0\n",
            "My testing loss: 0.764113187789917 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 288\n",
            "-----------\n",
            "My training loss: 0.3657717704772949 Training acc:85.0\n",
            "My testing loss: 0.7614917755126953 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 289\n",
            "-----------\n",
            "My training loss: 0.43899640440940857 Training acc:82.5\n",
            "My testing loss: 0.7584102153778076 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 290\n",
            "-----------\n",
            "My training loss: 0.3535763919353485 Training acc:86.25\n",
            "My testing loss: 0.7567631006240845 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 291\n",
            "-----------\n",
            "My training loss: 0.4489966928958893 Training acc:81.25\n",
            "My testing loss: 0.756402313709259 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 292\n",
            "-----------\n",
            "My training loss: 0.3759165406227112 Training acc:82.5\n",
            "My testing loss: 0.7575449347496033 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 293\n",
            "-----------\n",
            "My training loss: 0.3584447205066681 Training acc:86.25\n",
            "My testing loss: 0.7610151767730713 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 294\n",
            "-----------\n",
            "My training loss: 0.35700663924217224 Training acc:88.75\n",
            "My testing loss: 0.7669571042060852 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 295\n",
            "-----------\n",
            "My training loss: 0.3583623766899109 Training acc:87.5\n",
            "My testing loss: 0.7663906216621399 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 296\n",
            "-----------\n",
            "My training loss: 0.37687012553215027 Training acc:86.25\n",
            "My testing loss: 0.7645101547241211 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 297\n",
            "-----------\n",
            "My training loss: 0.4207178056240082 Training acc:82.5\n",
            "My testing loss: 0.7644689083099365 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 298\n",
            "-----------\n",
            "My training loss: 0.34624776244163513 Training acc:85.0\n",
            "My testing loss: 0.7635601758956909 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 299\n",
            "-----------\n",
            "My training loss: 0.3663403391838074 Training acc:83.75\n",
            "My testing loss: 0.7627990245819092 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 300\n",
            "-----------\n",
            "My training loss: 0.3609921634197235 Training acc:86.25\n",
            "My testing loss: 0.7677675485610962 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 301\n",
            "-----------\n",
            "My training loss: 0.35884231328964233 Training acc:87.5\n",
            "My testing loss: 0.7696042060852051 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 302\n",
            "-----------\n",
            "My training loss: 0.37660202383995056 Training acc:85.0\n",
            "My testing loss: 0.7673928737640381 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 303\n",
            "-----------\n",
            "My training loss: 0.3445471227169037 Training acc:87.5\n",
            "My testing loss: 0.7739747762680054 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 304\n",
            "-----------\n",
            "My training loss: 0.3743094205856323 Training acc:86.25\n",
            "My testing loss: 0.7724937796592712 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 305\n",
            "-----------\n",
            "My training loss: 0.36718037724494934 Training acc:87.5\n",
            "My testing loss: 0.7745957970619202 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 306\n",
            "-----------\n",
            "My training loss: 0.36213740706443787 Training acc:85.0\n",
            "My testing loss: 0.76755690574646 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 307\n",
            "-----------\n",
            "My training loss: 0.3671165406703949 Training acc:86.25\n",
            "My testing loss: 0.7649187445640564 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 308\n",
            "-----------\n",
            "My training loss: 0.39887991547584534 Training acc:82.5\n",
            "My testing loss: 0.7679155468940735 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 309\n",
            "-----------\n",
            "My training loss: 0.357455313205719 Training acc:88.75\n",
            "My testing loss: 0.7619856595993042 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 310\n",
            "-----------\n",
            "My training loss: 0.3532584607601166 Training acc:86.25\n",
            "My testing loss: 0.7651379108428955 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 311\n",
            "-----------\n",
            "My training loss: 0.3419093191623688 Training acc:87.5\n",
            "My testing loss: 0.7786033153533936 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 312\n",
            "-----------\n",
            "My training loss: 0.3932099938392639 Training acc:82.5\n",
            "My testing loss: 0.7766717672348022 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 313\n",
            "-----------\n",
            "My training loss: 0.3800022304058075 Training acc:86.25\n",
            "My testing loss: 0.7585549354553223 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 314\n",
            "-----------\n",
            "My training loss: 0.38054153323173523 Training acc:83.75\n",
            "My testing loss: 0.7584787011146545 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 315\n",
            "-----------\n",
            "My training loss: 0.34327432513237 Training acc:87.5\n",
            "My testing loss: 0.7523075342178345 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 316\n",
            "-----------\n",
            "My training loss: 0.3505590856075287 Training acc:87.5\n",
            "My testing loss: 0.7568451166152954 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 317\n",
            "-----------\n",
            "My training loss: 0.3537585735321045 Training acc:88.75\n",
            "My testing loss: 0.7622241377830505 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 318\n",
            "-----------\n",
            "My training loss: 0.34983548521995544 Training acc:88.75\n",
            "My testing loss: 0.7596536874771118 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 319\n",
            "-----------\n",
            "My training loss: 0.3530866801738739 Training acc:88.75\n",
            "My testing loss: 0.7570016980171204 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 320\n",
            "-----------\n",
            "My training loss: 0.34911707043647766 Training acc:87.5\n",
            "My testing loss: 0.7643445730209351 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 321\n",
            "-----------\n",
            "My training loss: 0.339080810546875 Training acc:87.5\n",
            "My testing loss: 0.7691827416419983 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 322\n",
            "-----------\n",
            "My training loss: 0.32487189769744873 Training acc:87.5\n",
            "My testing loss: 0.7776612043380737 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 323\n",
            "-----------\n",
            "My training loss: 0.3269456624984741 Training acc:87.5\n",
            "My testing loss: 0.7734472751617432 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 324\n",
            "-----------\n",
            "My training loss: 0.3557596802711487 Training acc:87.5\n",
            "My testing loss: 0.7710007429122925 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 325\n",
            "-----------\n",
            "My training loss: 0.32230085134506226 Training acc:86.25\n",
            "My testing loss: 0.793891966342926 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 326\n",
            "-----------\n",
            "My training loss: 0.3306093215942383 Training acc:86.25\n",
            "My testing loss: 0.7895391583442688 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 327\n",
            "-----------\n",
            "My training loss: 0.32579195499420166 Training acc:87.5\n",
            "My testing loss: 0.7723894119262695 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 328\n",
            "-----------\n",
            "My training loss: 0.35740411281585693 Training acc:90.0\n",
            "My testing loss: 0.7739758491516113 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 329\n",
            "-----------\n",
            "My training loss: 0.3384353816509247 Training acc:88.75\n",
            "My testing loss: 0.7731936573982239 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 330\n",
            "-----------\n",
            "My training loss: 0.36425521969795227 Training acc:85.0\n",
            "My testing loss: 0.7722927331924438 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 331\n",
            "-----------\n",
            "My training loss: 0.36181262135505676 Training acc:88.75\n",
            "My testing loss: 0.8013960123062134 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 332\n",
            "-----------\n",
            "My training loss: 0.3770783841609955 Training acc:85.0\n",
            "My testing loss: 0.7813689112663269 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 333\n",
            "-----------\n",
            "My training loss: 0.32461756467819214 Training acc:88.75\n",
            "My testing loss: 0.7745094895362854 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 334\n",
            "-----------\n",
            "My training loss: 0.33772012591362 Training acc:90.0\n",
            "My testing loss: 0.7711887955665588 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 335\n",
            "-----------\n",
            "My training loss: 0.3143802583217621 Training acc:88.75\n",
            "My testing loss: 0.7816729545593262 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 336\n",
            "-----------\n",
            "My training loss: 0.3841939866542816 Training acc:85.0\n",
            "My testing loss: 0.7734809517860413 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 337\n",
            "-----------\n",
            "My training loss: 0.34471508860588074 Training acc:90.0\n",
            "My testing loss: 0.7726693153381348 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 338\n",
            "-----------\n",
            "My training loss: 0.32882505655288696 Training acc:90.0\n",
            "My testing loss: 0.772597074508667 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 339\n",
            "-----------\n",
            "My training loss: 0.3070225417613983 Training acc:90.0\n",
            "My testing loss: 0.7860867381095886 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 340\n",
            "-----------\n",
            "My training loss: 0.3134816586971283 Training acc:90.0\n",
            "My testing loss: 0.7777817845344543 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 341\n",
            "-----------\n",
            "My training loss: 0.3006167709827423 Training acc:88.75\n",
            "My testing loss: 0.7680627107620239 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 342\n",
            "-----------\n",
            "My training loss: 0.36551520228385925 Training acc:85.0\n",
            "My testing loss: 0.7678971290588379 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 343\n",
            "-----------\n",
            "My training loss: 0.3358798027038574 Training acc:85.0\n",
            "My testing loss: 0.7619677782058716 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 344\n",
            "-----------\n",
            "My training loss: 0.3779371380805969 Training acc:85.0\n",
            "My testing loss: 0.7677546143531799 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 345\n",
            "-----------\n",
            "My training loss: 0.31150874495506287 Training acc:87.5\n",
            "My testing loss: 0.7866873145103455 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 346\n",
            "-----------\n",
            "My training loss: 0.32425403594970703 Training acc:87.5\n",
            "My testing loss: 0.7707008123397827 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 347\n",
            "-----------\n",
            "My training loss: 0.29934465885162354 Training acc:90.0\n",
            "My testing loss: 0.7752954959869385 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 348\n",
            "-----------\n",
            "My training loss: 0.30447474122047424 Training acc:88.75\n",
            "My testing loss: 0.7702124714851379 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 349\n",
            "-----------\n",
            "My training loss: 0.33866068720817566 Training acc:85.0\n",
            "My testing loss: 0.7698825597763062 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 350\n",
            "-----------\n",
            "My training loss: 0.34012743830680847 Training acc:87.5\n",
            "My testing loss: 0.7701929807662964 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 351\n",
            "-----------\n",
            "My training loss: 0.3773133456707001 Training acc:87.5\n",
            "My testing loss: 0.7796652913093567 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 352\n",
            "-----------\n",
            "My training loss: 0.30140241980552673 Training acc:87.5\n",
            "My testing loss: 0.7849918603897095 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 353\n",
            "-----------\n",
            "My training loss: 0.34994906187057495 Training acc:83.75\n",
            "My testing loss: 0.7691371440887451 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 354\n",
            "-----------\n",
            "My training loss: 0.30986374616622925 Training acc:90.0\n",
            "My testing loss: 0.7698190212249756 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 355\n",
            "-----------\n",
            "My training loss: 0.31463202834129333 Training acc:91.25\n",
            "My testing loss: 0.7753294706344604 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 356\n",
            "-----------\n",
            "My training loss: 0.2919667661190033 Training acc:90.0\n",
            "My testing loss: 0.7839561700820923 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 357\n",
            "-----------\n",
            "My training loss: 0.293896347284317 Training acc:88.75\n",
            "My testing loss: 0.7983930110931396 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 358\n",
            "-----------\n",
            "My training loss: 0.29264917969703674 Training acc:88.75\n",
            "My testing loss: 0.7878168821334839 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 359\n",
            "-----------\n",
            "My training loss: 0.2886340618133545 Training acc:88.75\n",
            "My testing loss: 0.7869125008583069 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 360\n",
            "-----------\n",
            "My training loss: 0.28757718205451965 Training acc:91.25\n",
            "My testing loss: 0.7844715118408203 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 361\n",
            "-----------\n",
            "My training loss: 0.2982003688812256 Training acc:88.75\n",
            "My testing loss: 0.7832458019256592 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 362\n",
            "-----------\n",
            "My training loss: 0.3163037896156311 Training acc:87.5\n",
            "My testing loss: 0.7849273085594177 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 363\n",
            "-----------\n",
            "My training loss: 0.31935179233551025 Training acc:85.0\n",
            "My testing loss: 0.7705602645874023 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 364\n",
            "-----------\n",
            "My training loss: 0.28513237833976746 Training acc:91.25\n",
            "My testing loss: 0.7653770446777344 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 365\n",
            "-----------\n",
            "My training loss: 0.2996080815792084 Training acc:90.0\n",
            "My testing loss: 0.778660774230957 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 366\n",
            "-----------\n",
            "My training loss: 0.30513596534729004 Training acc:91.25\n",
            "My testing loss: 0.7928481698036194 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 367\n",
            "-----------\n",
            "My training loss: 0.3261030614376068 Training acc:85.0\n",
            "My testing loss: 0.7908398509025574 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 368\n",
            "-----------\n",
            "My training loss: 0.2774202525615692 Training acc:88.75\n",
            "My testing loss: 0.8012853264808655 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 369\n",
            "-----------\n",
            "My training loss: 0.28944966197013855 Training acc:90.0\n",
            "My testing loss: 0.7839184999465942 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 370\n",
            "-----------\n",
            "My training loss: 0.28115415573120117 Training acc:92.5\n",
            "My testing loss: 0.7724358439445496 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 371\n",
            "-----------\n",
            "My training loss: 0.2822135090827942 Training acc:91.25\n",
            "My testing loss: 0.7640340328216553 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 372\n",
            "-----------\n",
            "My training loss: 0.301196813583374 Training acc:90.0\n",
            "My testing loss: 0.7711058259010315 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 373\n",
            "-----------\n",
            "My training loss: 0.2831651568412781 Training acc:90.0\n",
            "My testing loss: 0.7910737991333008 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 374\n",
            "-----------\n",
            "My training loss: 0.28587105870246887 Training acc:90.0\n",
            "My testing loss: 0.7902753949165344 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 375\n",
            "-----------\n",
            "My training loss: 0.3242388665676117 Training acc:88.75\n",
            "My testing loss: 0.7954829931259155 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 376\n",
            "-----------\n",
            "My training loss: 0.3435150682926178 Training acc:86.25\n",
            "My testing loss: 0.8130176663398743 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 377\n",
            "-----------\n",
            "My training loss: 0.29604169726371765 Training acc:91.25\n",
            "My testing loss: 0.7973784804344177 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 378\n",
            "-----------\n",
            "My training loss: 0.28284603357315063 Training acc:90.0\n",
            "My testing loss: 0.7781661748886108 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 379\n",
            "-----------\n",
            "My training loss: 0.33314716815948486 Training acc:88.75\n",
            "My testing loss: 0.7796590924263 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 380\n",
            "-----------\n",
            "My training loss: 0.28325557708740234 Training acc:91.25\n",
            "My testing loss: 0.779583752155304 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 381\n",
            "-----------\n",
            "My training loss: 0.28400295972824097 Training acc:91.25\n",
            "My testing loss: 0.7815877795219421 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 382\n",
            "-----------\n",
            "My training loss: 0.2916163504123688 Training acc:92.5\n",
            "My testing loss: 0.7941217422485352 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 383\n",
            "-----------\n",
            "My training loss: 0.30770343542099 Training acc:90.0\n",
            "My testing loss: 0.7967665195465088 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 384\n",
            "-----------\n",
            "My training loss: 0.27879858016967773 Training acc:91.25\n",
            "My testing loss: 0.796975314617157 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 385\n",
            "-----------\n",
            "My training loss: 0.30463501811027527 Training acc:90.0\n",
            "My testing loss: 0.8046988248825073 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 386\n",
            "-----------\n",
            "My training loss: 0.30845919251441956 Training acc:86.25\n",
            "My testing loss: 0.7925763726234436 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 387\n",
            "-----------\n",
            "My training loss: 0.2574268579483032 Training acc:90.0\n",
            "My testing loss: 0.8081665635108948 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 388\n",
            "-----------\n",
            "My training loss: 0.25501886010169983 Training acc:92.5\n",
            "My testing loss: 0.8143597841262817 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 389\n",
            "-----------\n",
            "My training loss: 0.27893194556236267 Training acc:91.25\n",
            "My testing loss: 0.8123998641967773 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 390\n",
            "-----------\n",
            "My training loss: 0.294599324464798 Training acc:88.75\n",
            "My testing loss: 0.8018306493759155 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 391\n",
            "-----------\n",
            "My training loss: 0.27020880579948425 Training acc:91.25\n",
            "My testing loss: 0.7970640063285828 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 392\n",
            "-----------\n",
            "My training loss: 0.29533666372299194 Training acc:91.25\n",
            "My testing loss: 0.8323858976364136 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 393\n",
            "-----------\n",
            "My training loss: 0.26772183179855347 Training acc:91.25\n",
            "My testing loss: 0.8031169772148132 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 394\n",
            "-----------\n",
            "My training loss: 0.2564202845096588 Training acc:90.0\n",
            "My testing loss: 0.8052753210067749 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 395\n",
            "-----------\n",
            "My training loss: 0.2739204466342926 Training acc:91.25\n",
            "My testing loss: 0.8144641518592834 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 396\n",
            "-----------\n",
            "My training loss: 0.26609736680984497 Training acc:92.5\n",
            "My testing loss: 0.8065776228904724 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 397\n",
            "-----------\n",
            "My training loss: 0.2540348768234253 Training acc:90.0\n",
            "My testing loss: 0.7980753183364868 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 398\n",
            "-----------\n",
            "My training loss: 0.2742637097835541 Training acc:90.0\n",
            "My testing loss: 0.8079103231430054 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 399\n",
            "-----------\n",
            "My training loss: 0.24899820983409882 Training acc:95.0\n",
            "My testing loss: 0.8132981061935425 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 400\n",
            "-----------\n",
            "My training loss: 0.24560177326202393 Training acc:92.5\n",
            "My testing loss: 0.8155601024627686 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 401\n",
            "-----------\n",
            "My training loss: 0.24283473193645477 Training acc:92.5\n",
            "My testing loss: 0.8047242760658264 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 402\n",
            "-----------\n",
            "My training loss: 0.2918817400932312 Training acc:87.5\n",
            "My testing loss: 0.8030447959899902 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 403\n",
            "-----------\n",
            "My training loss: 0.28863853216171265 Training acc:91.25\n",
            "My testing loss: 0.7960012555122375 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 404\n",
            "-----------\n",
            "My training loss: 0.28937187790870667 Training acc:88.75\n",
            "My testing loss: 0.7894281148910522 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 405\n",
            "-----------\n",
            "My training loss: 0.2690759301185608 Training acc:90.0\n",
            "My testing loss: 0.7955715656280518 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 406\n",
            "-----------\n",
            "My training loss: 0.2520465552806854 Training acc:92.5\n",
            "My testing loss: 0.784253716468811 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 407\n",
            "-----------\n",
            "My training loss: 0.2594611346721649 Training acc:91.25\n",
            "My testing loss: 0.7832146883010864 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 408\n",
            "-----------\n",
            "My training loss: 0.24504850804805756 Training acc:91.25\n",
            "My testing loss: 0.7873728275299072 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 409\n",
            "-----------\n",
            "My training loss: 0.2575192153453827 Training acc:91.25\n",
            "My testing loss: 0.8027772307395935 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 410\n",
            "-----------\n",
            "My training loss: 0.2813006043434143 Training acc:87.5\n",
            "My testing loss: 0.8044772148132324 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 411\n",
            "-----------\n",
            "My training loss: 0.2613912522792816 Training acc:91.25\n",
            "My testing loss: 0.7867559194564819 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 412\n",
            "-----------\n",
            "My training loss: 0.2639826536178589 Training acc:92.5\n",
            "My testing loss: 0.7948962450027466 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 413\n",
            "-----------\n",
            "My training loss: 0.2465149611234665 Training acc:93.75\n",
            "My testing loss: 0.7965477705001831 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 414\n",
            "-----------\n",
            "My training loss: 0.23929162323474884 Training acc:93.75\n",
            "My testing loss: 0.8026297092437744 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 415\n",
            "-----------\n",
            "My training loss: 0.22521023452281952 Training acc:93.75\n",
            "My testing loss: 0.7866405248641968 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 416\n",
            "-----------\n",
            "My training loss: 0.24851298332214355 Training acc:91.25\n",
            "My testing loss: 0.7859858274459839 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 417\n",
            "-----------\n",
            "My training loss: 0.25238463282585144 Training acc:93.75\n",
            "My testing loss: 0.8118194341659546 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 418\n",
            "-----------\n",
            "My training loss: 0.29500433802604675 Training acc:86.25\n",
            "My testing loss: 0.8233380317687988 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 419\n",
            "-----------\n",
            "My training loss: 0.24341228604316711 Training acc:91.25\n",
            "My testing loss: 0.8255900740623474 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 420\n",
            "-----------\n",
            "My training loss: 0.26803669333457947 Training acc:92.5\n",
            "My testing loss: 0.8069393038749695 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 421\n",
            "-----------\n",
            "My training loss: 0.2286541908979416 Training acc:93.75\n",
            "My testing loss: 0.8041762113571167 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 422\n",
            "-----------\n",
            "My training loss: 0.23423297703266144 Training acc:92.5\n",
            "My testing loss: 0.8072987794876099 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 423\n",
            "-----------\n",
            "My training loss: 0.2277974933385849 Training acc:92.5\n",
            "My testing loss: 0.821501612663269 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 424\n",
            "-----------\n",
            "My training loss: 0.22130714356899261 Training acc:93.75\n",
            "My testing loss: 0.8167661428451538 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 425\n",
            "-----------\n",
            "My training loss: 0.23186595737934113 Training acc:91.25\n",
            "My testing loss: 0.7967986464500427 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 426\n",
            "-----------\n",
            "My training loss: 0.25647783279418945 Training acc:91.25\n",
            "My testing loss: 0.7964563369750977 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 427\n",
            "-----------\n",
            "My training loss: 0.24737463891506195 Training acc:91.25\n",
            "My testing loss: 0.8167465925216675 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 428\n",
            "-----------\n",
            "My training loss: 0.27608272433280945 Training acc:88.75\n",
            "My testing loss: 0.8165820837020874 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 429\n",
            "-----------\n",
            "My training loss: 0.25254228711128235 Training acc:93.75\n",
            "My testing loss: 0.8046915531158447 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 430\n",
            "-----------\n",
            "My training loss: 0.23855829238891602 Training acc:92.5\n",
            "My testing loss: 0.8052416443824768 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 431\n",
            "-----------\n",
            "My training loss: 0.22634167969226837 Training acc:95.0\n",
            "My testing loss: 0.8166381120681763 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 432\n",
            "-----------\n",
            "My training loss: 0.29787740111351013 Training acc:86.25\n",
            "My testing loss: 0.8122275471687317 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 433\n",
            "-----------\n",
            "My training loss: 0.23374222218990326 Training acc:91.25\n",
            "My testing loss: 0.8471276760101318 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 434\n",
            "-----------\n",
            "My training loss: 0.24317649006843567 Training acc:92.5\n",
            "My testing loss: 0.8132990598678589 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 435\n",
            "-----------\n",
            "My training loss: 0.2279655933380127 Training acc:95.0\n",
            "My testing loss: 0.8060653209686279 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 436\n",
            "-----------\n",
            "My training loss: 0.28438931703567505 Training acc:91.25\n",
            "My testing loss: 0.8127541542053223 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 437\n",
            "-----------\n",
            "My training loss: 0.2560931146144867 Training acc:92.5\n",
            "My testing loss: 0.7986804246902466 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 438\n",
            "-----------\n",
            "My training loss: 0.26066848635673523 Training acc:93.75\n",
            "My testing loss: 0.7978439331054688 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 439\n",
            "-----------\n",
            "My training loss: 0.22434495389461517 Training acc:93.75\n",
            "My testing loss: 0.8106244802474976 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 440\n",
            "-----------\n",
            "My training loss: 0.22888369858264923 Training acc:93.75\n",
            "My testing loss: 0.8173461556434631 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 441\n",
            "-----------\n",
            "My training loss: 0.25729653239250183 Training acc:90.0\n",
            "My testing loss: 0.8077058792114258 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 442\n",
            "-----------\n",
            "My training loss: 0.27052924036979675 Training acc:90.0\n",
            "My testing loss: 0.7973033785820007 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 443\n",
            "-----------\n",
            "My training loss: 0.2397323101758957 Training acc:95.0\n",
            "My testing loss: 0.8202325701713562 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 444\n",
            "-----------\n",
            "My training loss: 0.23176582157611847 Training acc:93.75\n",
            "My testing loss: 0.834155797958374 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 445\n",
            "-----------\n",
            "My training loss: 0.20740416646003723 Training acc:95.0\n",
            "My testing loss: 0.8202108144760132 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 446\n",
            "-----------\n",
            "My training loss: 0.22745676338672638 Training acc:91.25\n",
            "My testing loss: 0.8252619504928589 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 447\n",
            "-----------\n",
            "My training loss: 0.2365478128194809 Training acc:96.25\n",
            "My testing loss: 0.8275599479675293 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 448\n",
            "-----------\n",
            "My training loss: 0.24445371329784393 Training acc:93.75\n",
            "My testing loss: 0.8484045267105103 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 449\n",
            "-----------\n",
            "My training loss: 0.24104325473308563 Training acc:91.25\n",
            "My testing loss: 0.8520694971084595 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 450\n",
            "-----------\n",
            "My training loss: 0.21978609263896942 Training acc:92.5\n",
            "My testing loss: 0.8355353474617004 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 451\n",
            "-----------\n",
            "My training loss: 0.20897486805915833 Training acc:93.75\n",
            "My testing loss: 0.8146597146987915 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 452\n",
            "-----------\n",
            "My training loss: 0.20651467144489288 Training acc:95.0\n",
            "My testing loss: 0.8104477524757385 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 453\n",
            "-----------\n",
            "My training loss: 0.21457190811634064 Training acc:95.0\n",
            "My testing loss: 0.819989800453186 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 454\n",
            "-----------\n",
            "My training loss: 0.21350856125354767 Training acc:93.75\n",
            "My testing loss: 0.8327911496162415 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 455\n",
            "-----------\n",
            "My training loss: 0.20029592514038086 Training acc:93.75\n",
            "My testing loss: 0.8249181509017944 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 456\n",
            "-----------\n",
            "My training loss: 0.2183847874403 Training acc:91.25\n",
            "My testing loss: 0.820158839225769 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 457\n",
            "-----------\n",
            "My training loss: 0.20425252616405487 Training acc:96.25\n",
            "My testing loss: 0.8308858275413513 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 458\n",
            "-----------\n",
            "My training loss: 0.21364454925060272 Training acc:95.0\n",
            "My testing loss: 0.837633490562439 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 459\n",
            "-----------\n",
            "My training loss: 0.26263880729675293 Training acc:90.0\n",
            "My testing loss: 0.8311416506767273 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 460\n",
            "-----------\n",
            "My training loss: 0.2041902393102646 Training acc:95.0\n",
            "My testing loss: 0.82530677318573 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 461\n",
            "-----------\n",
            "My training loss: 0.1948690563440323 Training acc:95.0\n",
            "My testing loss: 0.8290237188339233 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 462\n",
            "-----------\n",
            "My training loss: 0.20191577076911926 Training acc:95.0\n",
            "My testing loss: 0.8243225812911987 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 463\n",
            "-----------\n",
            "My training loss: 0.2184375375509262 Training acc:95.0\n",
            "My testing loss: 0.8262275457382202 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 464\n",
            "-----------\n",
            "My training loss: 0.21519963443279266 Training acc:92.5\n",
            "My testing loss: 0.8280512094497681 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 465\n",
            "-----------\n",
            "My training loss: 0.23613527417182922 Training acc:91.25\n",
            "My testing loss: 0.844197154045105 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 466\n",
            "-----------\n",
            "My training loss: 0.21369127929210663 Training acc:91.25\n",
            "My testing loss: 0.8418896794319153 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 467\n",
            "-----------\n",
            "My training loss: 0.2046600878238678 Training acc:93.75\n",
            "My testing loss: 0.8470402956008911 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 468\n",
            "-----------\n",
            "My training loss: 0.20405244827270508 Training acc:93.75\n",
            "My testing loss: 0.8587631583213806 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 469\n",
            "-----------\n",
            "My training loss: 0.20988495647907257 Training acc:95.0\n",
            "My testing loss: 0.8460028767585754 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 470\n",
            "-----------\n",
            "My training loss: 0.2026231288909912 Training acc:96.25\n",
            "My testing loss: 0.8508706092834473 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 471\n",
            "-----------\n",
            "My training loss: 0.19334028661251068 Training acc:93.75\n",
            "My testing loss: 0.8478947877883911 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 472\n",
            "-----------\n",
            "My training loss: 0.1910771131515503 Training acc:95.0\n",
            "My testing loss: 0.854640543460846 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 473\n",
            "-----------\n",
            "My training loss: 0.23312711715698242 Training acc:91.25\n",
            "My testing loss: 0.8508204817771912 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 474\n",
            "-----------\n",
            "My training loss: 0.21031475067138672 Training acc:95.0\n",
            "My testing loss: 0.8398987054824829 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 475\n",
            "-----------\n",
            "My training loss: 0.23334577679634094 Training acc:90.0\n",
            "My testing loss: 0.8372607231140137 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 476\n",
            "-----------\n",
            "My training loss: 0.2548070251941681 Training acc:90.0\n",
            "My testing loss: 0.841072678565979 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 477\n",
            "-----------\n",
            "My training loss: 0.18501053750514984 Training acc:96.25\n",
            "My testing loss: 0.8324976563453674 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 478\n",
            "-----------\n",
            "My training loss: 0.21108900010585785 Training acc:95.0\n",
            "My testing loss: 0.8401082754135132 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 479\n",
            "-----------\n",
            "My training loss: 0.19620293378829956 Training acc:95.0\n",
            "My testing loss: 0.8467509746551514 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 480\n",
            "-----------\n",
            "My training loss: 0.18156790733337402 Training acc:95.0\n",
            "My testing loss: 0.8416610956192017 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 481\n",
            "-----------\n",
            "My training loss: 0.19089625775814056 Training acc:93.75\n",
            "My testing loss: 0.854820728302002 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 482\n",
            "-----------\n",
            "My training loss: 0.19614024460315704 Training acc:95.0\n",
            "My testing loss: 0.850293755531311 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 483\n",
            "-----------\n",
            "My training loss: 0.23062913119792938 Training acc:91.25\n",
            "My testing loss: 0.8588575124740601 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 484\n",
            "-----------\n",
            "My training loss: 0.229019433259964 Training acc:91.25\n",
            "My testing loss: 0.8460065126419067 Training acc:68.75\n",
            "\n",
            "\n",
            "\n",
            "My epoch 485\n",
            "-----------\n",
            "My training loss: 0.18143866956233978 Training acc:96.25\n",
            "My testing loss: 0.8306087255477905 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 486\n",
            "-----------\n",
            "My training loss: 0.19132402539253235 Training acc:95.0\n",
            "My testing loss: 0.8391181826591492 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 487\n",
            "-----------\n",
            "My training loss: 0.19127383828163147 Training acc:93.75\n",
            "My testing loss: 0.8663234710693359 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 488\n",
            "-----------\n",
            "My training loss: 0.22117851674556732 Training acc:92.5\n",
            "My testing loss: 0.8582545518875122 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 489\n",
            "-----------\n",
            "My training loss: 0.17732630670070648 Training acc:96.25\n",
            "My testing loss: 0.8460984230041504 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 490\n",
            "-----------\n",
            "My training loss: 0.19860592484474182 Training acc:96.25\n",
            "My testing loss: 0.8587871789932251 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 491\n",
            "-----------\n",
            "My training loss: 0.21462106704711914 Training acc:95.0\n",
            "My testing loss: 0.862856388092041 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 492\n",
            "-----------\n",
            "My training loss: 0.1992597132921219 Training acc:95.0\n",
            "My testing loss: 0.8766551613807678 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 493\n",
            "-----------\n",
            "My training loss: 0.17240945994853973 Training acc:97.5\n",
            "My testing loss: 0.8782718181610107 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 494\n",
            "-----------\n",
            "My training loss: 0.19855795800685883 Training acc:92.5\n",
            "My testing loss: 0.8710350394248962 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 495\n",
            "-----------\n",
            "My training loss: 0.2001468390226364 Training acc:96.25\n",
            "My testing loss: 0.8693745732307434 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 496\n",
            "-----------\n",
            "My training loss: 0.18771864473819733 Training acc:95.0\n",
            "My testing loss: 0.8935818672180176 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 497\n",
            "-----------\n",
            "My training loss: 0.2013971358537674 Training acc:95.0\n",
            "My testing loss: 0.8726729154586792 Training acc:75.0\n",
            "\n",
            "\n",
            "\n",
            "My epoch 498\n",
            "-----------\n",
            "My training loss: 0.17439894378185272 Training acc:93.75\n",
            "My testing loss: 0.868803083896637 Training acc:81.25\n",
            "\n",
            "\n",
            "\n",
            "My epoch 499\n",
            "-----------\n",
            "My training loss: 0.17797353863716125 Training acc:93.75\n",
            "My testing loss: 0.8662099838256836 Training acc:81.25\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}